# Data Quality

## Have confidence in your data

Most companies detect issues after their team has used bad data to make decisions or trigger campaigns. Quickly take action on every invalid event with in-app reporting and daily email digests.

### Align all the teams in your company around a single data dictionary

In the [Normalized datalayer](normalized-datalayer.md) interface, you will be able to define the schema of your data and define the validation rules that will feed your data quality workflow.

### Automate the QA process

Writing [event specification](normalized-datalayer.md) allows you to automate the QA process, to feed the in the [Source data quality](data-quality.md) dashboard, but also to define realtime alerts to react quickly when errors occur on your data.

### Fix your data in realtime

To react quickly to data errors, while your IT team corrects the problem at source, you can rely on the [live data transformation feature](data-cleansing/), aka [Data cleansing](data-cleansing/).

### Data delivery

Having a good data quality on each source is essential, but being able to check also the [quality of the data transmission](../destinations/event-delivery.md) is at least as important. For each destination, you can view the [event delivery history](../destinations/event-delivery.md#3-error-details), quickly identify errors and define [realtime alerts](../destinations/event-delivery.md#alerting) with a personnalized thresold.
